{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/azureuser/.cache/huggingface/token\n",
      "Login successful\n",
      "Connection String: BlobEndpoint=https://blobstorageffpanhhmq7wy3.blob... (truncated for security)\n",
      "BlobServiceClient initialized successfully.\n",
      "Connected to account: Standard_LRS\n",
      "Container Name: ncc\n",
      "ContainerClient initialized successfully.\n",
      "Container already exists or error: The specified container already exists.\n",
      "RequestId:92711b93-d01e-00c7-26f0-044ee4000000\n",
      "Time:2024-09-12T08:46:19.2092492Z\n",
      "ErrorCode:ContainerAlreadyExists\n",
      "Content: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>ContainerAlreadyExists</Code><Message>The specified container already exists.\n",
      "RequestId:92711b93-d01e-00c7-26f0-044ee4000000\n",
      "Time:2024-09-12T08:46:19.2092492Z</Message></Error>\n",
      "Container 'ncc' exists and is accessible.\n",
      "Blob '1000examples.csv' uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "import os\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")\n",
    "\n",
    "import pandas as pd\n",
    "# Load the dataset with streaming enabled\n",
    "import itertools\n",
    "\n",
    "\n",
    "data = load_dataset(\"NbAiLab/NCC\", streaming=True)\n",
    "\n",
    "# Take only a small amount of data, e.g., 100 samples\n",
    "data = pd.DataFrame(list(itertools.islice(data['train'], 1000)))\n",
    "import re\n",
    "\n",
    "# Define a function to clean the 'id' field\n",
    "def clean_id(val):\n",
    "    if isinstance(val, str):\n",
    "        # Replace all disallowed characters with an underscore\n",
    "        return re.sub(r'[^A-Za-z0-9_\\-]', '_', val)\n",
    "    return val\n",
    "\n",
    "# Apply the function to the 'id' column\n",
    "df['id'] = df['id'].apply(clean_id)\n",
    "# Convert DataFrame to CSV in-memory\n",
    "csv_buffer = io.StringIO()\n",
    "df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Set up connection string and container details\n",
    "connection_string = os.environ['BLOB_CONNECTION_STRING']\n",
    "container_name = \"ncc\"\n",
    "blob_name = \"1000examples.csv\"  # The name of the blob you want to create\n",
    "\n",
    "\n",
    "try:\n",
    "    # Debug: Print connection string for validation\n",
    "    print(f\"Connection String: {connection_string[:50]}... (truncated for security)\")\n",
    "\n",
    "    # Initialize BlobServiceClient\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    print(\"BlobServiceClient initialized successfully.\")\n",
    "\n",
    "    # Debug: Check account name\n",
    "    account_info = blob_service_client.get_account_information()\n",
    "    print(f\"Connected to account: {account_info['sku_name']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize BlobServiceClient: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    # Debug: Check container name\n",
    "    print(f\"Container Name: {container_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get a container client\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(\"ContainerClient initialized successfully.\")\n",
    "\n",
    "        # Create the container if it doesn't exist\n",
    "    try:\n",
    "        container_client.create_container()\n",
    "    except Exception as e:\n",
    "        print(f\"Container already exists or error: {str(e)}\")\n",
    "    # Debug: Check if the container exists\n",
    "    if container_client.exists():\n",
    "        print(f\"Container '{container_name}' exists and is accessible.\")\n",
    "    else:\n",
    "        print(f\"Container '{container_name}' does not exist or is not accessible.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize ContainerClient: {str(e)}\")\n",
    "    \n",
    "# Initialize BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Get a container client\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "\n",
    "\n",
    "# Create a BlobClient\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "# Upload the in-memory CSV to the blob\n",
    "blob_client.upload_blob(csv_buffer.getvalue(), overwrite=True)\n",
    "\n",
    "print(f\"Blob '{blob_name}' uploaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
