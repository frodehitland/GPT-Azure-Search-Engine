{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b",
   "metadata": {},
   "source": [
    "# How to deal with complex/large Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d",
   "metadata": {},
   "source": [
    "In the previous notebook, we developed a solution for various types of files and data formats commonly found in organizations, and this covers big majority of the use cases. However, you will find that there are issues when dealing with questions that require answers from complex files. The complexity of these files arises from their length and the way information is distributed within them. Large documents are always a challenge for Search Engines.\n",
    "\n",
    "One example of such complex files is Technical Specification Guides or Product Manuals, which can span hundreds of pages and contain information in the form of images, tables, forms, and more. Books are also complex due to their length and the presence of images or tables.\n",
    "\n",
    "These files are typically in PDF format. To better handle these PDFs, we need a smarter parsing method that treats each document as a special source and processes them page by page (1 page = 1 chunk). The objective is to obtain more accurate and faster answers from our system. Fortunately, there are usually not many of these types of documents in an organization, allowing us to make exceptions and treat them differently.\n",
    "\n",
    "If your use case is just PDFs, for example, you can just use [PyPDF library](https://pypi.org/project/pypdf/) or [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0), vectorize using OpenAI API and push the content to a vector-based index. And this is problably the simplest and fastest way to go.  However if your use case entails connecting to a datalake, or Sharepoint libraries or any other document data source with thousands of documents with multiple file types and that can change dynamically, then you would want to use the Ingestion and Document Cracking and AI-Enrichment capabilities of Azure Search engine, Notebooks 1-3, and avoid a lot of painful custom code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f6044e-463f-4988-bc46-a3c3d641c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "from common.utils import parse_pdf, read_pdf_files, text_to_base64\n",
    "from common.prompts import DOCSEARCH_PROMPT\n",
    "from common.utils import CustomAzureSearchRetriever\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "os.makedirs(\"data/books/\",exist_ok=True)\n",
    "    \n",
    "\n",
    "BLOB_CONTAINER_NAME = \"usecases\"\n",
    "BASE_CONTAINER_URL = \"https://blobstorageffpanhhmq7wy3.blob.core.windows.net/\" + BLOB_CONTAINER_NAME + \"/\"\n",
    "LOCAL_FOLDER = \"./data/usecases/\"\n",
    "\n",
    "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60208725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search=\"example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c8adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://blobstorageffpanhhmq7wy3.blob.core.windows.net/books/StyleTTS2.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-09-13T16:22:30Z&st=2024-09-13T08:22:30Z&spr=https&sig=mnoIDbS7Z3ooFM%2BVbIFU9TbrIGfG14ss1Lt5HD1l3io%3D&#search=we%model%the%speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331692ba-b68e-4b99-9bae-5057da9a389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594ff0d4-56e3-4bed-843d-28c7a092069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 75\n",
    "embedder = AzureOpenAIEmbeddings(deployment=os.environ[\"EMBEDDING_DEPLOYMENT_NAME\"], chunk_size=batch_size, \n",
    "                                 max_retries=2, \n",
    "                                 retry_min_seconds= 60,\n",
    "                                 retry_max_seconds= 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87c647-158c-4f85-b569-5b9462f06c83",
   "metadata": {},
   "source": [
    "## 1 - Manual Document Cracking with Push to Vector-based Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75551868-1546-421b-a14e-e42618d88e61",
   "metadata": {},
   "source": [
    "Within our demo storage account, we have a container named `books`, which holds 5 books of different lengths, languages, and complexities. Let's create a `cogsrch-index-books-vector` and load it with the pages of all these books.\n",
    "\n",
    "We begin by downloading these books to our local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0999e24b-6a75-4fa1-9a5f-426cf0f0bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [\"BigVGAN.pdf\", \n",
    "         \"PL-BERT.pdf\",\n",
    "         \"StarGANv2.pdf\",\n",
    "         \"StyleTTS2.pdf\"\n",
    "         ]\n",
    "\n",
    "usecases = [ '2323-EQU-Y-SA-0014_EQU design basis.PDF' , 'TR2258 Digital Factory - Information and Exchange Models.PDF' , 'TR2381 LCI Requirements Master for FPSO.PDF',\n",
    "'TR1212 SAS Operator Station HMI.PDF' ,     'TR2325 Piping Detail Standard.PDF'       ,                      'TR3032 Field instrumentation.PDF']\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9",
   "metadata": {},
   "source": [
    "Let's download the files to the local `./data/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554f0b7-fee8-4446-a155-5d22dc0f0888",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_context = ssl.create_default_context()\n",
    "\n",
    "\n",
    "for book in tqdm(usecases):\n",
    "    print(BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN'])\n",
    "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
    "    req = urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)\n",
    "\n",
    "    print(req.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cc0db-9dae-45f2-8943-2b6fa32fcc75",
   "metadata": {},
   "source": [
    "### What to use: pyPDF or AI Documment Intelligence API (Form Recognizer)?\n",
    "\n",
    "In `utils.py` there is a **parse_pdf()** function. This utility function can parse local files using PyPDF library and can also parse local or from_url PDFs files using Azure AI Document Intelligence (Former Form Recognizer).\n",
    "\n",
    "If `form_recognizer=False`, the function will parse the PDF using the python pyPDF library, which 75% of the time does a good job.<br>\n",
    "\n",
    "Setting `form_recognizer=True`, is the best (and slower) parsing method using AI Documment Intelligence API (former known as Form Recognizer). You can specify the prebuilt model to use, the default is `model=\"prebuilt-document\"`. However, if you have a complex document with tables, charts and figures , you can try\n",
    "`model=\"prebuilt-layout\"`, and it will capture all of the nuances of each page (it takes longer of course).\n",
    "\n",
    "**Note: Many PDFs are scanned images. For example, any signed contract that was scanned and saved as PDF will NOT be parsed by pyPDF. Only AI Documment Intelligence API will work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c63a2f-7a53-4346-8a1f-483cfd159d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "book_pages_map = dict()\n",
    "\n",
    "# Function to process each book\n",
    "def process_book(book):\n",
    "    try:\n",
    "        print(f\"Extracting Text from {book}...\")\n",
    "\n",
    "        # Capture the start time for the individual book\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Create the full path to the book\n",
    "        book_path = Path(LOCAL_FOLDER) / book\n",
    "\n",
    "        # Parse the PDF (assuming parse_pdf is a custom function)\n",
    "        book_map = parse_pdf(file=str(book_path), form_recognizer=False, verbose=True)\n",
    "\n",
    "        # Capture the elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Print the time it took to process the book and the number of pages\n",
    "        print(f\"Parsing {book} took: {elapsed_time:.2f} seconds\")\n",
    "        print(f\"{book} contained {len(book_map)} pages\\n\")\n",
    "\n",
    "        # Return the book name and the parsed result (book_map)\n",
    "        return book, book_map\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {book}: {e}\")\n",
    "        return book, None\n",
    "\n",
    "# Capture the start time for the entire process\n",
    "overall_start_time = time.time()\n",
    "\n",
    "# Process the books in parallel using ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Map results of the parallel processing to 'results'\n",
    "    results = executor.map(process_book, usecases)\n",
    "\n",
    "# Store the results in the book_pages_map dictionary (only store successfully processed books)\n",
    "book_pages_map = {book: book_map for book, book_map in results if book_map}\n",
    "\n",
    "# Capture the end time for the entire process\n",
    "overall_end_time = time.time()\n",
    "\n",
    "# Calculate the total elapsed time for all books\n",
    "total_elapsed_time = overall_end_time - overall_start_time\n",
    "print(f\"Total time for parsing all books: {total_elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0a722-ae0c-4b57-802a-518f5d4d93fd",
   "metadata": {},
   "source": [
    "Now let's check a random page of each book to make sure the parsing was done correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5d62f-b664-4662-a6c9-a1eb2a3c5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Loop over each book and its corresponding map\n",
    "for bookname, bookmap in book_pages_map.items():\n",
    "    try:\n",
    "        # Ensure the random index is within the bounds of the bookmap (number of pages)\n",
    "        if len(bookmap) > 1:  # Make sure there are at least 10 pages\n",
    "            random_page_index = random.randint(5, min(50, len(bookmap)-1))  # Ensure index doesn't exceed the available pages\n",
    "            \n",
    "            # Get the content of the randomly selected page\n",
    "            page_content = bookmap[random_page_index]\n",
    "\n",
    "            # Check if the page_content has at least 3 elements to safely access [2]\n",
    "            if len(page_content) > 2 and isinstance(page_content[2], str):  # Ensure there's a valid chunk at index 2\n",
    "                chunk_text = page_content[2][:120]  # Get the first 120 characters\n",
    "                print(f\"{bookname}\\nChunk text (from page {random_page_index}): {chunk_text}...\\n\")\n",
    "            else:\n",
    "                print(f\"{bookname}\\nPage {random_page_index} does not have enough content or a valid chunk at index [2].\\n\")\n",
    "        else:\n",
    "            print(f\"{bookname} does not have enough pages to select a random chunk.\\n\")\n",
    "    \n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError for {bookname}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {bookname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcdc1ee-71fc-49d2-8e7c-0964bc3a4370",
   "metadata": {},
   "source": [
    "As we can see above, all books were parsed except `Pere_Riche_Pere_Pauvre.pdf` (this book is \"Rich Dad, Poor Dad\" written in French), why? Well, as we mentioned above, this book was scanned, so each page is an image and with a very unique font. We need a good PDF parser with good OCR capabilities in order to extract the content of this PDF. \n",
    "Let's try to parse this book again, but this time using Azure Document Intelligence API (former Form Recognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c6bc2-467c-4418-aa7e-ef89a1e20e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "book = \"2323-EQU-Y-SA-0014_EQU design basis.pdf\"\n",
    "book_path = LOCAL_FOLDER+book\n",
    "book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\",from_url=False, verbose=True)\n",
    "book_pages_map[book]= book_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9c5bb-c44b-4a4d-9780-591f9f8d128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if book in book_pages_map:\n",
    "    book_map = book_pages_map[book]\n",
    "    if len(book_map) > 1:\n",
    "        random_page = random.randint(1, min(50, len(book_map)-1))  # Ensure index doesn't exceed the available pages\n",
    "        if len(book_map[random_page]) > 2 and isinstance(book_map[random_page][2], str):  # Ensure there's a valid chunk at index [2]\n",
    "            print(book, \"\\n\", \"chunk text:\", book_map[random_page][2][:80], \"...\\n\")\n",
    "        else:\n",
    "            print(f\"{book} does not have enough content or a valid chunk at index [2].\")\n",
    "    else:\n",
    "        print(f\"{book} does not have enough pages to select a random chunk.\")\n",
    "else:\n",
    "    print(f\"{book} is not defined in book_pages_map.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c279dfb-4fed-41b8-89e1-0ca2cefbcdc9",
   "metadata": {},
   "source": [
    "As demonstrated above, Azure Document Intelligence proves to be superior to pyPDF. **For production scenarios, we strongly recommend using Azure Document Intelligence consistently**. When doing so, it's important to make a wise choice between the available models, such as \"prebuilt-document,\" \"prebuilt-layout,\" or others. You can find more information on model selection [HERE](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/choose-model-feature?view=doc-intel-3.0.0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e",
   "metadata": {},
   "source": [
    "## Create Vector-based index\n",
    "\n",
    "\n",
    "Now that we have the content of the book's chunks (each page of each book) in the dictionary `book_pages_map`, let's create the Vector index in our Azure Search Engine where this content is going to land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "usecase_index_name = \"srch-index-usecases\"\n",
    "books_index_name = \"srch-index-books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b07e84b-d306-4bc9-9124-e64f252dd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Azure Search Vector-based Index\n",
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faab899-977b-40d0-b36e-26f75ac07e54",
   "metadata": {},
   "source": [
    "\n",
    "Please note the following points regarding the index:\n",
    "\n",
    "- The ParentKey field is absent.\n",
    "- The page_num field is present.\n",
    "\n",
    "The absence of the ParentKey field is due to the utilization of a PUSH method, rather than a PULL method. This approach indicates that we are not leveraging the integrated indexing provided by the Azure AI Search engine. Instead, we are engaging in the process of parsing, performing OCR, and manually creating and pushing the content along with its vectors.\n",
    "\n",
    "This manual parsing process involves the use of either, the pyPDF library, or the Azure Document Intelligence API. These APIs allow for the segmentation of content by page rather than by a specified number of characters, which is the method employed by the Azure AI search indexer. Consequently, this enables the inclusion of page_num as a field in our index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d63e68-69a5-4b3b-8eb0-86da02cb7230",
   "metadata": {},
   "source": [
    "REST API version 2023-10-01-Preview supports external and internal vectorization. This Notebook assumes an external vectorization strategy. This API also supports:\n",
    "    \n",
    "- vectorSearch algorithms, hnsw and exhaustiveKnn nearest neighbors, with parameters for indexing and scoring.\n",
    "- vectorProfiles for multiple combinations of algorithm configurations.\n",
    "\n",
    "Vector search algorithms include **exhaustive k-nearest neighbors (KNN)** and **Hierarchical Navigable Small World (HNSW)**. Exhaustive KNN performs a brute-force search that scans the entire vector space. HNSW performs an approximate nearest neighbor (ANN) search. While KNN provides exact nearest neighbor search results with high accuracy, its computational cost and poor scalability make it impractical for large datasets or real-time applications. HNSW, on the other hand, offers a highly efficient and scalable solution for nearest neighbor searches by finding approximate nearest neighbors quickly, making it more suitable for large-scale and high-dimensional data applications.\n",
    "\n",
    "\n",
    "check [HERE](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-10-01-Preview%2Crest-2023-11-01%2Cpush%2Cportal-check-index) for the details of the vector configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_payload = {\n",
    "    \"name\": book_index_name,\n",
    "    \"vectorSearch\": {\n",
    "        \"algorithms\": [  # We are showing here 3 types of search algorithms configurations that you can do\n",
    "             {\n",
    "                 \"name\": \"my-hnsw-config-1\",\n",
    "                 \"kind\": \"hnsw\",\n",
    "                 \"hnswParameters\": {\n",
    "                     \"m\": 4,\n",
    "                     \"efConstruction\": 400,\n",
    "                     \"efSearch\": 500,\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "                 \"name\": \"my-hnsw-config-2\",\n",
    "                 \"kind\": \"hnsw\",\n",
    "                 \"hnswParameters\": {\n",
    "                     \"m\": 8,\n",
    "                     \"efConstruction\": 800,\n",
    "                     \"efSearch\": 800,\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "                 \"name\": \"my-eknn-config\",\n",
    "                 \"kind\": \"exhaustiveKnn\",\n",
    "                 \"exhaustiveKnnParameters\": {\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             }\n",
    "        ],\n",
    "        \"vectorizers\": [\n",
    "            {\n",
    "                \"name\": \"openai\",\n",
    "                \"kind\": \"azureOpenAI\",\n",
    "                \"azureOpenAIParameters\":\n",
    "                {\n",
    "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "                    \"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
    "                    \"deploymentId\" : os.environ['EMBEDDING_DEPLOYMENT_NAME'],\n",
    "                    \"modelName\" : os.environ['EMBEDDING_DEPLOYMENT_NAME']\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"profiles\": [  # profiles is the diferent kind of combinations of algos and vectorizers\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-1\",\n",
    "             \"algorithm\": \"my-hnsw-config-1\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            },\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-2\",\n",
    "             \"algorithm\": \"my-hnsw-config-2\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            },\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-3\",\n",
    "             \"algorithm\": \"my-eknn-config\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"semantic\": {\n",
    "        \"configurations\": [\n",
    "            {\n",
    "                \"name\": \"my-semantic-config\",\n",
    "                \"prioritizedFields\": {\n",
    "                    \"titleField\": {\n",
    "                        \"fieldName\": \"title\"\n",
    "                    },\n",
    "                    \"prioritizedContentFields\": [\n",
    "                        {\n",
    "                            \"fieldName\": \"chunk\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"prioritizedKeywordsFields\": []\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
    "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
    "        {\n",
    "            \"name\": \"chunkVector\",\n",
    "            \"type\": \"Collection(Edm.Single)\",\n",
    "            \"dimensions\": 3072,\n",
    "            \"vectorSearchProfile\": \"my-vector-profile-3\", # we picked profile 3 to show that this index uses eKNN vs HNSW (on prior notebooks)\n",
    "            \"searchable\": \"true\",\n",
    "            \"retrievable\": \"true\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        }\n",
    "        \n",
    "    ],\n",
    "}\n",
    "\n",
    "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36691ff0-c4c8-49d0-bfa8-3e076ece0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to debug errors\n",
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7dda9-4725-410e-9465-54f0298fc758",
   "metadata": {},
   "source": [
    "## Upload the Document chunks and its vectors to the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0",
   "metadata": {},
   "source": [
    "The following code will iterate over each chunk of each book and use the Azure Search Rest API upload method to insert each document with its corresponding vector (using OpenAI embedding model) to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a94911cf-c95f-4306-8574-b56296f29b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a batch of pages\n",
    "def process_batch(bookname, pages):\n",
    "    try:\n",
    "        contents = [page[2] for page in pages]\n",
    "        chunk_vectors = embedder.embed_documents(contents)\n",
    "        \n",
    "        upload_payload = {\"value\": []}\n",
    "        for i, page in enumerate(pages):\n",
    "            page_num = page[0] + 1\n",
    "            content = page[2]\n",
    "            book_url = BASE_CONTAINER_URL + bookname\n",
    "            \n",
    "            payload = {\n",
    "                \"@search.action\": \"upload\",\n",
    "                \"id\": text_to_base64(bookname + str(page_num)),\n",
    "                \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
    "                \"chunk\": content,\n",
    "                \"chunkVector\": chunk_vectors[i],\n",
    "                \"name\": bookname,\n",
    "                \"location\": book_url,\n",
    "                \"page_num\": page_num\n",
    "            }\n",
    "            upload_payload[\"value\"].append(payload)\n",
    "        \n",
    "        r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name + \"/docs/index\",\n",
    "                          data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Failed to upload batch of pages from {bookname}: {r.status_code}\")\n",
    "            print(r.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception processing batch of pages from {bookname}: {e}\")\n",
    "        time.sleep(10)  # Wait before retrying\n",
    "        process_batch(bookname, pages)  # Retry the same batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a3171-f8f0-4070-8a54-8a540828333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for bookname, bookmap in book_pages_map.items():\n",
    "        print(\"Uploading chunks from\", bookname)\n",
    "        # Split bookmap into chunks of size chunk_size\n",
    "        for i in tqdm(range(0, len(bookmap), batch_size)):\n",
    "            batch = bookmap[i:i + batch_size]\n",
    "            process_batch(bookname, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cddcf-af7b-4006-a047-853fc7a66be3",
   "metadata": {},
   "source": [
    "## Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b408798-5527-44ca-9dba-cad2ee726aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Considerations in design for future tie-in(s) and tie-back(s). whats the reservoir pressure in the cambroiol central and Cappahayden West block?\"\n",
    "QUESTION1 = \"Ablation study for verifying the effectiveness of MLM, P2G, and BERT compared to StyleTTS w/ PL-BERT.\"\n",
    "QUESTION2 = \"How did BigVGAN perform in terms of PESQ score vs WaveGlow-256?\"\n",
    "QUESTION3 = \"what is the acronym of the main point of Made to Stick book\"\n",
    "QUESTION4= \"Tell me a python example of how do I push documents with vectors to an index using the python SDK?\"\n",
    "QUESTION5 = \"who won the soccer worldcup in 1994?\" # this question should have no answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b182ade-0ddd-47a1-b1eb-2cbf435c317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "usecases_index_name = \"srch-index-usecases\"\n",
    "books_index_name = \"srch-index-books\"\n",
    "\n",
    "indexes = [books_index_name]\n",
    "k=20 # in this index k corresponds to the top pages as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50eecb2-ce26-4127-a62b-79735b937046",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = CustomAzureSearchRetriever(indexes=[usecases_index_name], topK=k, reranker_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "410ff796-dab1-4817-a3a5-82eeff6c0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 2500\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS).configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    default_key=\"gpt35\",\n",
    "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0, max_tokens=COMPLETION_TOKENS),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c2851-08c5-4e7c-ba7b-4655a6021e1e",
   "metadata": {},
   "source": [
    "In `utils.py` we created the **CustomAzureSearchRetriever** class that we will use going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f47c69-44d8-48e3-974e-7989b4a8b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | DOCSEARCH_PROMPT  # Passes the 4 variables above to the prompt template\n",
    "    | llm   # Passes the finished prompt to the LLM\n",
    "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765df250-af7f-46c9-8d7a-15c0522969ec",
   "metadata": {},
   "source": [
    "#### With GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73f34192-519d-45b9-a0e2-a8b2de51ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a8761d-2c1e-4369-b7c4-c3571a0793e9",
   "metadata": {},
   "source": [
    "#### With GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b77511-b178-4c9b-9fa5-fdddb0d3e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Retrieve the SAS token from the environment (or define it directly)\n",
    "sas_token = os.environ['BLOB_SAS_TOKEN']  # Assuming the token starts with '?'\n",
    "\n",
    "# Regex pattern to match .pdf/.PDF links (with trailing characters like ) and spaces)\n",
    "pdf_pattern = re.compile(r'(https?://[^\\s\\)]+\\.pdf)', re.IGNORECASE)\n",
    "\n",
    "# Set to track processed URLs\n",
    "processed_urls = set()\n",
    "\n",
    "# Initialize a buffer to store chunks that may contain split URLs\n",
    "buffer = ''\n",
    "\n",
    "# Process each chunk in the stream\n",
    "for chunk in chain.with_config(configurable={\"model\": \"gpt4\"}).stream(\n",
    "    {\"question\": QUESTION, \"language\": \"English\"}):\n",
    "    \n",
    "    # Append the new chunk to the buffer\n",
    "    buffer += chunk\n",
    "\n",
    "    # Use regex to find all occurrences of .pdf/.PDF links in the buffer\n",
    "    matches = pdf_pattern.findall(buffer)\n",
    "\n",
    "    #if matches:\n",
    "        #print(f\"Matches found: {matches}\")  # Debug: Print found matches\n",
    "\n",
    "    for pdf_url in matches:\n",
    "        # Check if this URL has already been processed\n",
    "        if pdf_url not in processed_urls:\n",
    "            # Append the SAS token to the URL\n",
    "            pdf_url_with_token = pdf_url  + sas_token\n",
    "\n",
    "            # Replace the URL in the buffer with the one that includes the SAS token\n",
    "            buffer = buffer.replace(pdf_url, pdf_url_with_token)\n",
    "\n",
    "            # Mark this URL as processed\n",
    "            processed_urls.add(pdf_url)\n",
    "\n",
    "            # Debug output to see what's happening\n",
    "            #print(f\"\\nFound PDF URL: {pdf_url}\\nReplaced with: {pdf_url_with_token}\\n\")\n",
    "\n",
    "\n",
    "# Output the processed buffer\n",
    "print(buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941796c-7655-4888-a358-8a62e380bd7e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook we learned how to deal with complex and large Documents and make them available for Q&A over them using [Hybrid Search](https://learn.microsoft.com/en-us/azure/search/search-get-started-vector#hybrid-search) (text + vector search).\n",
    "\n",
    "We also learned the power of Azure Document Inteligence API and why it is recommended for production scenarios where manual Document parsing (instead of Azure Search Indexer Document Cracking) is necessary.\n",
    "\n",
    "Using Azure AI Search with its Vector capabilities and hybrid search features eliminates the need for other vector databases such as Weaviate, Qdrant, Milvus, Pinecone, and so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9a7d1-f029-416b-8eb2-00a8afb9151d",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "So far we have learned how to use OpenAI vectors and completion APIs in order to get an excelent answer from our documents stored in Azure AI Search. This is the backbone for a GPT Smart Search Engine.\n",
    "\n",
    "However, we are missing something: **How to have a conversation with this engine?**\n",
    "\n",
    "On the next Notebook, we are going to understand the concept of **memory**. This is necessary in order to have a chatbot that can establish a conversation with the user. Without memory, there is no real conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed733fb-dec4-4a8f-bff0-c7cbbcc0328e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6e963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
